Подключитесь по SSH к мастер-узлу и выполните следующую команду для инициализации нового кластера kubernetes (с заданными параметрами можно ознакомиться изучив файл */etc/kubernetes/kubeadm-config.yaml*, его содержимое также приведено в сценарии Ansible, который Вы использовали для подготовки узлов)
```
sudo kubeadm init --config /etc/kubernetes/kubeadm-config.yaml
```
Просмотрите вывод kubeadm (это действительно может быть полезно, так как он содержит информацию о том, какие дальнейшие действия надо предпринять для получения работоспособного кластера, что впрочем и так будет Вам сообщено далее по мере выполнения данной лабораторной работы) и найдите команду для добавления рабочих узлов (не control-plane), скопируйте ее для дальнейшего использования на других узлах, она начинается с ```kubeadm join ...```

Скопируйте файл конфигурации кластера для kubectl, чтобы он мог автоматически считывать его (**Запомните, копируемый файл ```admin.conf``` содержит всю необходимую информацию для получения полного доступа к кластеру, его надо беречь**) 
```
cd k8s/
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```
Теперь мы готовы осуществить первые взаимодействия с кластером, давайте сделаем это, для начала убедимся что кластер работает и мы имеем доступ к нему, выполнив 
```
kubectl cluster-info
```
Если все в порядке, в ответ Вы получите информацию о статусе и том, по какому адресу (точнее будет сказать, URL) доступны плоскость управления (control plane) кластера (читай API-сервер) и сервис внутрикластерного DNS.

Давайте проверим теперь состояние узлов нашего кластера, состоящего пока что из единственного мастер-узла, сделать это можно командой 
```
kubectl get nodes
```
Узел находится в статусе *NotReady*, однако больше ничего конкретного относительно данной ситуации мы узнать этой командой не сможем, даже если попросим более подробный вывод: ```kubectl get nodes -o wide```. Отложим пока ситуацию с узлом на некоторое время в сторону и попробуем выяснить, какие поды работают (и работают ли) сейчас. Выполним команду 
```
kubectl get pods
``` 
и получим ответ, что ресурсов (собственно, самих подов) в пространстве имен по умолчанию (default namespace) не обнаружено. Так как в команде не было указано пространство имен, то и результат мы получили только для пространства имен по умолчанию, которое сейчас пустует, а чтобы получить информацию о ресурсах в других пространствах, их надо указать в запросе kubectl. Для того, чтобы понять, какие у нас пространства имен существуют "из коробки", получим их список командой
```
kubectl get namespaces
```
В выводе помимо уже знакомого default будет интересующее нас в данный момент kube-system, в котором располагаются объекты, созданные самим кластером, в первую очередь связанные с компонентами плоскости управления.

Попробуем еще раз получить информацию о подах, теперь уже с конкретикой что мы хотим получить данные из пространства имен *kube-system*
```
kubectl get pods -n kube-system
```
Полученная информация должна нас успокоить в том плане, что компоненты плоскости управления кластера запущены и успешно функционируют, однако поды CoreDNS почему-то зависли в состоянии ожидания (Pending), давайте узнаем точную причину происходящего. В этом может помочь команда *kubectl describe*, она используется, чтобы получить подробную информацию о конкретном объекте (объектах), в нашем случае о поде CoreDNS. (*Крайне полезная информация: Чтобы нормально читать вывод этой и некоторых других команд, может потребоваться достаточно сильно увеличить размер окна терминала и возможно понизить размер шрифта*) Полная команда будет выглядеть так (вместо *<pod_name>* подставьте имя любого пода CoreDNS):
```
kubectl describe pods/<pod_name> -n kube-system
``` 
И самый конец вывода, секция События (Events) прямо говорит нам о том, что планировщик не смог найти подходящий узел по причине того, что на единственном доступном узле висит "черная метка", ограничение (taint), к которому у данного пода нет допуска (tolerations). В этом можно убедиться, сравнив пункты из вышележащей секции Tolerations в выведенных данных с вызвавшим проблему ограничением.

Теперь посмотрим, а как же собственно говоря, можно получить информацию о всех однотипных ресурсах из всех пространств имен кластера, на примере  всех существующих на текущий момент в кластере подов, на самом деле очень просто:
```
kubectl get pods -A
```
*Полезная информация: узнать какие еще ресурсы кластера существуют помимо ```pod и node```,  можно выполнив команду ```kubectl api-resources```*

Итак, настало время разобраться наконец, что не так с нашим узлом, для этого нам снова поможет команда для подробного вывода состояния объекта 
```
kubectl describe nodes
```
в ее выводе найдем секцию Conditions, а в ней пункт Ready. Данные в колонке Message достаточно прямолинейно говорят о существующей проблеме: не готова к работе сеть подов, так как не проинициализирован плагин CNI. Еще выше можно найти информацию о текущих ограничениях на узле (секция Taints). Зафиксируйте информацию о том, какое еще ограничение висит на узле (преподаватели могут спросить при сдаче работы) и подумайте, для чего оно существует (подсказка: все увиденные нами ранее поды имеют специально прописанный в их спецификациях допуск (толерантность) к этому ограничению, пользовательские нагрузки по умолчанию не имеют допусков).

Теперь, когда мы выявили причину всех теекущих бед с кластером, надо срочно подумать об установке и настройке CNI-плагина, который отвечает за сеть подов, а если быть точнее, за выделение им IP адресов, обеспечение связности между подами на разных узлах (посредством маршрутизации либо туннелирования) и опционально за применение сетевых политик, разграничивающих доступ. В данной работе будет использоваться один из наиболее известных CNI-плагинов, Calico.

Подробно разобрать его принцип работы, особенности и тому подобное мы в рамках данной работы не сможем, поэтому ограничимся краткой информацией: в нашем случае 
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml
kubectl apply -f ./calico.yaml
